#!/bin/bash

#source env
source ./environment.conf
source ./lib/public.framework
source ./lib/public.workload

#run scenario
./scenario/scenario_xxx 

#case name
caseName=xxx-xxx

#run case
echo "$caseName - begin" 
echo "$caseName - sbumit job"
#$SPARK_HOME/bin/spark-submit --conf spark.master=spark://$SMASTER_HNAME:7077 --deploy-mode client --class job.submit.control.submitSleepTasks $SLEEPJAR 3 6000 &>> $caseLogDir/tmpOut &
echo "$caseName - waite case done"
#sleep 25
echo "$caseName - check result"
#jobStatus=`getJobStatus $caseLogDir/tmpOut "Job done"`
#echo "$caseName - job status: $jobStatus"
echo "$caseName - write report"
#if [ -z "$jobStatus" ]; then
#    echo "--- $caseName, job cannot finish, failed.">> $testReport
#elif [ -n "$jobStatus" ]; then
#    echo "--- $caseName, job done, passed." >> $testReport
#fi	
echo "$caseName - end" 

recoverAndExit 0;
