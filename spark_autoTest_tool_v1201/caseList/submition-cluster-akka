#!/bin/bash

#source env
source ./environment.conf
source ./lib/public.framework
source ./lib/public.workload

#run scenario
#./scenario/scenario_fifo_conf 

#case name
caseName=submition-cluster-akka

#run case
echo "$caseName - begin" 
echo "$caseName - sbumit job"
#$SPARK_HOME/bin/spark-submit --conf spark.master=spark://$SMASTER_HNAME:7077 --deploy-mode cluster  --class job.submit.control.submitSleepTasks $SLEEPJAR 3 6000 >>  $caseLogDir/stdout 2>> $caseLogDir/stderr
$SPARK_HOME/bin/spark-submit --conf spark.master=spark://$SMASTER_HNAME:7077 --deploy-mode cluster  --class job.submit.control.submitSleepTasks $SLEEPJAR 3 6000 &>> $caseLogDir/tmpOut
sleep 10
driverStatus=`getAkkaDriverStatus $caseLogDir/tmpOut`
echo "$caseName - driver status: $driverStatus"
drivername=`getAkkaDriverName $caseLogDir/tmpOut`
echo "$caseName - driver name: $drivername" 
sleep 20
jobStatus=`getJobStatus $SPARK_HOME/work/$drivername/stdout "Job done"`
echo "$caseName - job status: $jobStatus"
echo "$caseName - write report"
if [ -z "$jobStatus" ]; then
    echo "--- $caseName, job cannot finish, failed.">> $testReport
elif [ -n "$jobStatus" ]; then
    echo "--- $caseName, job done, passed." >> $testReport
fi	
echo "$caseName - end" 

recoverAndExit 0;
