#!/bin/bash

#source env
source ./environment.conf
source ./lib/public.framework
source ./lib/public.workload

#run scenario
./scenario/scenario_fifo_conf 

#case name
#caseName=submition-cluster-restful

#run case
echo "$caseName - begin" 
echo "$caseName - sbumit job"
#$SPARK_HOME/bin/spark-submit --conf spark.master=spark://$SMASTER_HNAME:6066 --deploy-mode cluster  --class job.submit.control.submitSleepTasks $SLEEPJAR 3 6000 >>  $caseLogDir/stdout 2>> $caseLogDir/stderr
$SPARK_HOME/bin/spark-submit --conf spark.master=spark://$SMASTER_HNAME:6066 --deploy-mode cluster  --class job.submit.control.submitSleepTasks $SLEEPJAR 3 6000 &>>  $caseLogDir/tmpOut
sleep 5
driverStatus=`getRestApiDriverStatus $caseLogDir/tmpOut`
echo "$caseName - driver success to submit: $driverStatus"
drivername=`getRestApiDriverName $caseLogDir/tmpOut`
echo "$caseName - driver name: $drivername" 
sleep 20
jobStatus=`getJobStatus $SPARK_HOME/work/$drivername/stdout "Job done"`
echo "$caseName - job status: $jobStatus"
echo "$caseName - write report"
if [ -z "$jobStatus" ]; then
    echo "--- $caseName, job cannot finish, failed.">> $testReport
elif [ -n "$jobStatus" ]; then
    echo "--- $caseName, job done, passed." >> $testReport
fi	
echo "$caseName - end" 

recoverAndExit 0;
