Readme of spark automation tool


What we have:
   Readme       
   Start.regression.sh : script to start test, with a parameter, case list dir or one single case
   Environment.conf :  environment need user input, like home info
   Lib : functions 
     |------------ framework.func :  function about framework
     |------------ worklaod.func :  function about running workload
     ...
   Scenario : env setting scenrio, each case need it to set up the envrionment
     |------------ scenario_hierarchy_conf : scenario for hierarchy policy
     |------------ scenario_fairshare_conf : scenario for fairshare policy
     |------------ scenario_fifo_conf : scenario for fifo policy
     |------------ scenario_template : scenario template
     ... 
   caseList : case list
     |------------ case.template  : template, no executable right
     |------------ submition-client-akka
     |------------ submition-cluster-akka
     |------------ submition-cluster-restful
     ...
   Reports : test report created during the test
     |------------ report-1448976077 : test report named with cteated date
     |------------ report-1448976377 : test report about with cteated date
     ...
   autoTestExamples.jar : jar file with samples needed
   Conf : configuration files case may use



How it works:

 ./Start.regression.sh  caseListDir/caseFile
      |
      |<----- source conf/environment.conf   export user environment 
      |<----- source lib/xxx            export functions
      |
      |------> create a report dir for this regression
      |------> create a case list (according caseListDir/caseFile) under report dir
      |
      |___ run cases in case list
             |
             |------ run scenario user chosen to setup setting case needed
             |------ run cases script user write, record result
      _______|
      |
      |------> write report base on case result
      |
      0 

How to use it - case runner
 Step 1: set environment in conf/environment.conf
   ################################
   ###      Mandatory ENV       ###
   ################################
   export SPARK_HOME=
   export HADOOP_HOME=
   export SYM_MASTER_HOST=
   export TEST_TOOL_HOME=
   export JAVA_HOME=
   ###############################
   ###   Env script MAY use    ###
   ###############################
   export SLOTS_PER_HOST=12     #for schedule and reclaim
   export HOST_NUM=1                #for HA ...
   export SUBMIT_USER=root
   ...

 Step 2: run regression
   ./start.regression.sh caseList
   please find report at /.../spark_autoTest_tool/reports/report-1449045551/testReport.txt
   please find case list at /.../spark_autoTest_tool/reports/report-1449045551/caseList
   please find detail case log under /.../spark_autoTest_tool/reports/report-1449045551/logs/

 Step 3: check report and logs

How to use it - case developer
 Step0: check out code from github
 Step1: set envrionment
 Step2: choose a scenario or write a new one based on template
 Step3: make a sub directory under caseList/ and add cases based on template there
 Step4: test and debug your single case by ¡°./start.regression.sh caseFile¡±
 Step5: code review
 Step6: commit code to github

