#!/bin/sh

################################
###      Mandatory ENV       ###
################################
export SPARK_HOME=/scratch/qa1/zmzhao/spark/workshop_141/spark-1.4.1-bin-hadoop2.6
export HADOOP_HOME=/scratch/qa1/zmzhao/spark/workshop_141/hadoop-2.6.0
export SMASTER_HNAME=zmzhao05.eng.platformlab.ibm.com
export AUTOTOOL_HOME=/scratch/qa1/zmzhao/spark/workshop_141/spark-1.4.1-bin-hadoop2.6/spark_autoTest_tool
export JAVA_HOME=/pcc/app/Linux_jdk1.7.0_x86_64
###############################
###   Env script MAY use    ###
###############################
export SLOTS_ON_EACH_NODE=12     #for schedule and reclaim
export NODE_NUM=1                #for HA ...
export SUSER=root
#export SUSER02=root             #for mulitple user case
export TEST_IN_DEBUG_MODE=no     #no: remove tmp log files during the test
#export TEST_IN_DEBUG_MODE=yes   #yes: leave tmp log files   
export SLEEPJAR=$AUTOTOOL_HOME/autoTestExamples.jar
export SPARK_CONF_DIR=$SPARK_HOME/conf

###############################
###   common function  
###############################
function createReport ()
{
  reportDir=$AUTOTOOL_HOME/reports/report-`date +%s`
  mkdir $reportDir
  mkdir $reportDir/logs
  testReport=$reportDir/testReport.txt
  export reportDir
  export testReport
}
function backupSparkConf ()
{
  cp $SPARK_CONF_DIR/spark-env.sh $SPARK_CONF_DIR/spark-env.sh.org.bak
  cp $SPARK_CONF_DIR/spark-defaults.conf $SPARK_CONF_DIR/spark-defaults.conf.org.bak
  cp $SPARK_CONF_DIR/log4j.properties $SPARK_CONF_DIR/log4j.properties.org.bak
  return 0
}
function recoverAndExit ()
{
   mv $SPARK_CONF_DIR/spark-env.sh.org.bak $SPARK_CONF_DIR/spark-env.sh
   mv $SPARK_CONF_DIR/spark-defaults.conf.org.bak $SPARK_CONF_DIR/spark-defaults.conf
   mv $SPARK_CONF_DIR/log4j.properties.org.bak $SPARK_CONF_DIR/log4j.properties
   if [ -n $1 ]; then
      exit $1 
   else
      exit 0
   fi
}

